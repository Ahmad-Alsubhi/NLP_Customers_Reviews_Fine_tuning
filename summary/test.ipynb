{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a7mad/Desktop/git_lab/ironhack/ironhack/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸ Ù…Ø­Ù„ÙŠÙ‹Ø§\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(\"my_bart_summary\")\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained(\"my_bart_summary\")\n",
    "gen_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../claster/done.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a7mad/Desktop/git_lab/ironhack/ironhack/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a7mad/Desktop/git_lab/ironhack/ironhack/lib/python3.10/site-packages/transformers/generation/utils.py:1666: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# ========== Ø§Ù„ØªØ­Ù…ÙŠÙ„ ==========\n",
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ RoBERTa Ø§Ù„Ù…ØµÙ†Ù\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(\"../claster/my_roberta\")\n",
    "cls_model = AutoModel.from_pretrained(\"../claster/my_roberta\")\n",
    "cls_model.eval()\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ KMeans\n",
    "kmeans_model = joblib.load(\"../claster/kmeans_model.pkl\")\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ BART Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠ Ø§Ù„Ù…Ø­ÙÙˆØ¸ Ù…Ø­Ù„ÙŠÙ‹Ø§\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(\"my_bart_summary\")\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained(\"my_bart_summary\")\n",
    "gen_model.eval()\n",
    "\n",
    "# Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø§Ø³ØªØ±Ø§Øª\n",
    "cluster_names = {\n",
    "    0: \"Entry-Level and Kids Fire Tablets\",\n",
    "    1: \"Batteries, Laptop Gear, and Basic Accessories\",\n",
    "    2: \"Streaming Devices and E-Readers\",\n",
    "    3: \"Advanced E-Readers and Smart Assistants\",\n",
    "    4: \"Echo Speakers and Smart Home Hubs\"\n",
    "}\n",
    "\n",
    "# ========== Ø¯ÙˆØ§Ù„ ==========\n",
    "def get_cluster(text):\n",
    "    inputs = cls_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        output = cls_model(**inputs)\n",
    "    token_embeddings = output.last_hidden_state\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    mask_exp = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    summed = torch.sum(token_embeddings * mask_exp, 1)\n",
    "    summed_mask = torch.clamp(mask_exp.sum(1), min=1e-9)\n",
    "    mean = (summed / summed_mask).cpu().numpy()\n",
    "    cluster_num = kmeans_model.predict(mean)[0]\n",
    "    return cluster_names[cluster_num]\n",
    "\n",
    "def generate_summary(user_text):\n",
    "    category = get_cluster(user_text)\n",
    "    df1 = df[df[\"cluster\"] == category]\n",
    "\n",
    "    # Ø£ÙØ¶Ù„ 3 Ù…Ù†ØªØ¬Ø§Øª\n",
    "    top_rated = df1[df1[\"reviews.rating\"] == 5]\n",
    "    top_3 = top_rated[\"name\"].value_counts().head(3).index.tolist()\n",
    "    differences = \"\\n\".join([f\"- {i+1}. {name}\" for i, name in enumerate(top_3)])\n",
    "\n",
    "    # Ø§Ù„Ø´ÙƒØ§ÙˆÙ‰\n",
    "    complaints = {}\n",
    "    negative = df1[(df1[\"reviews.rating\"] <= 2) & (df1[\"reviews.doRecommend\"] == False)]\n",
    "    for prod in top_3:\n",
    "        texts = negative[negative[\"name\"] == prod][\"reviews.text\"]\n",
    "        sample = texts.sample(min(3, len(texts))) if len(texts) > 0 else []\n",
    "        complaints[prod] = \" | \".join(sample)\n",
    "\n",
    "    # Ø£Ø³ÙˆØ£ Ù…Ù†ØªØ¬\n",
    "    worst_df = df1[df1[\"reviews.doRecommend\"] == False]\n",
    "    if not worst_df.empty:\n",
    "        worst_product = worst_df[\"name\"].value_counts().idxmax()\n",
    "        worst_reasons = worst_df[worst_df[\"name\"] == worst_product][\"reviews.text\"].sample(min(3, len(worst_df))).tolist()\n",
    "    else:\n",
    "        worst_product = \"ØºÙŠØ± Ù…ØªÙˆÙØ±\"\n",
    "        worst_reasons = [\"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ø¨Ø§Ø¨ ÙˆØ§Ø¶Ø­Ø©.\"]\n",
    "\n",
    "    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª\n",
    "    prompt = f\"\"\"\n",
    "ğŸ“¦ Cluster: {category}\n",
    "\n",
    "âœ… Top 3 Products:\n",
    "{differences}\n",
    "\n",
    "ğŸ” Key Differences:\n",
    "Explain how these products differ in features, design, or value.\n",
    "\n",
    "âš ï¸ Top Complaints:\n",
    "- {top_3[0]}: {complaints.get(top_3[0], '')}\n",
    "- {top_3[1]}: {complaints.get(top_3[1], '')}\n",
    "- {top_3[2]}: {complaints.get(top_3[2], '')}\n",
    "\n",
    "ğŸš« Worst Product:\n",
    "{worst_product}\n",
    "Reasons to avoid:\n",
    "{\" | \".join(worst_reasons)}\n",
    "\"\"\"\n",
    "\n",
    "    # Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BART\n",
    "    inputs = gen_tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024)\n",
    "    summary_ids = gen_model.generate(inputs[\"input_ids\"], max_length=300, num_beams=4, early_stopping=True)\n",
    "    output = gen_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "# ========== Gradio ÙˆØ§Ø¬Ù‡Ø© ==========\n",
    "gr.Interface(\n",
    "    fn=generate_summary,\n",
    "    inputs=gr.Textbox(label=\"ğŸ“ Ø§ÙƒØªØ¨ ÙˆØµÙ Ø§Ù„Ù…Ù†ØªØ¬ Ø£Ùˆ Ù…Ø±Ø§Ø¬Ø¹Ø©\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"ğŸ“Š ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø§Ù„ ØªÙˆØµÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬Ø§Øª\",\n",
    "    description=\"ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒÙ„Ø§Ø³ØªØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ØŒ Ø«Ù… ÙŠÙˆÙ„Ø¯ Ù…Ù‚Ø§Ù„Ø§Ù‹ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ 3 Ù…Ù†ØªØ¬Ø§ØªØŒ Ø£Ù‡Ù… Ø§Ù„Ø´ÙƒØ§ÙˆÙ‰ØŒ ÙˆØ£Ø³ÙˆØ£ Ù…Ù†ØªØ¬ ÙˆÙ„Ù…Ø§Ø°Ø§ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡.\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon Echo Show Alexa-enabled Bluetooth Speaker with 7\" Screen                                                                     845\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
